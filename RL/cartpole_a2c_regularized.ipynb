{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coax\n",
    "import gym\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from coax.value_losses import mse\n",
    "from RPPRegularizer import RPPRegularizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# the name of this script\n",
    "name = 'a2c'\n",
    "\n",
    "# the cart-pole MDP\n",
    "# env = gym.make('CartPole-v0')\n",
    "env = gym.make(\"rpp_gym:InclinedCartpole-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = coax.wrappers.TrainMonitor(env, name=name, tensorboard_dir=f\"./data/tensorboard/{name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.spec.max_episode_steps = 200\n",
    "# env.spec.reward_threshold = 195.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|root|INFO] Initing EMLP (Haiku)\n",
      "[a2c|root|INFO] Linear W components:400 rep:96P+48P⊗V+20P⊗V²+8P⊗V³+4P⊗V⁴\n",
      "[a2c|root|INFO] P cache miss\n",
      "[a2c|root|INFO] Solving basis for P, for G=Z(2)\n",
      "[a2c|root|INFO] P⊗V cache miss\n",
      "[a2c|root|INFO] Solving basis for P⊗V, for G=Z(2)\n",
      "[a2c|root|INFO] P⊗V² cache miss\n",
      "[a2c|root|INFO] Solving basis for P⊗V², for G=Z(2)\n",
      "[a2c|root|INFO] P⊗V³ cache miss\n",
      "[a2c|root|INFO] Solving basis for P⊗V³, for G=Z(2)\n",
      "[a2c|root|INFO] P⊗V⁴ cache miss\n",
      "[a2c|root|INFO] Solving basis for P⊗V⁴, for G=Z(2)\n",
      "[a2c|root|INFO] V cache miss\n",
      "[a2c|root|INFO] Solving basis for V, for G=Z(2)\n",
      "[a2c|root|INFO] V² cache miss\n",
      "[a2c|root|INFO] Solving basis for V², for G=Z(2)\n",
      "[a2c|root|INFO] V³ cache miss\n",
      "[a2c|root|INFO] Solving basis for V³, for G=Z(2)\n",
      "[a2c|root|INFO] V⁴ cache miss\n",
      "[a2c|root|INFO] Solving basis for V⁴, for G=Z(2)\n",
      "[a2c|root|INFO] Linear W components:10000 rep:576V⁰+576V+384V²+216V³+121V⁴+44V⁵+14V⁶+4V⁷+V⁸\n",
      "[a2c|root|INFO] V⁵ cache miss\n",
      "[a2c|root|INFO] Solving basis for V⁵, for G=Z(2)\n",
      "[a2c|root|INFO] V⁶ cache miss\n",
      "[a2c|root|INFO] Solving basis for V⁶, for G=Z(2)\n",
      "[a2c|root|INFO] V⁷ cache miss\n",
      "[a2c|root|INFO] Solving basis for V⁷, for G=Z(2)\n",
      "[a2c|root|INFO] V⁸ cache miss\n",
      "[a2c|root|INFO] Solving basis for V⁸, for G=Z(2)\n",
      "[a2c|root|INFO] Linear W components:200 rep:24V+12V²+5V³+2V⁴+V⁵\n",
      "[a2c|root|INFO] Initing EMLP (Haiku)\n",
      "[a2c|root|INFO] Linear W components:400 rep:96P+48P⊗V+20P⊗V²+8P⊗V³+4P⊗V⁴\n",
      "[a2c|root|INFO] Linear W components:10000 rep:576V⁰+576V+384V²+216V³+121V⁴+44V⁵+14V⁶+4V⁷+V⁸\n",
      "[a2c|root|INFO] Linear W components:100 rep:24V⁰+12V+5V²+2V³+V⁴\n"
     ]
    }
   ],
   "source": [
    "from emlp import T, Scalar\n",
    "from emlp.groups import SO, S, O, Trivial,Z\n",
    "import emlp.nn.haiku as ehk\n",
    "from emlp.reps import Rep\n",
    "from emlp.nn import gated,gate_indices,uniform_rep\n",
    "from math import prod\n",
    "from representations import PseudoScalar\n",
    "from mixed_emlp_haiku import MixedEMLP\n",
    "\n",
    "## Trivial\n",
    "# group=Trivial(2)\n",
    "# rep_in = T(0)*prod(env.observation_space.shape)\n",
    "# rep_out = T(0)*env.action_space.n#prod(env.action_space.shape)\n",
    "\n",
    "## Reflection\n",
    "group=Z(2)\n",
    "rep_in = PseudoScalar()*prod(env.observation_space.shape)\n",
    "rep_out = T(1)#*env.action_space.n#prod(env.action_space.shape)\n",
    "\n",
    "nn_pi = ehk.EMLP(rep_in,rep_out,group,ch=100,num_layers=2)\n",
    "nn_v = ehk.EMLP(rep_in,T(0),group,ch=100,num_layers=2)\n",
    "\n",
    "# nn_pi = ehk.MLP(rep_in,rep_out(group),group,ch=100,num_layers=2)\n",
    "# nn_v = ehk.MLP(rep_in,T(0),group,ch=100,num_layers=2)\n",
    "\n",
    "# nn_pi = MixedEMLP(rep_in,rep_out(group),group,ch=100,num_layers=2)\n",
    "# nn_v = MixedEMLP(rep_in,T(0),group,ch=100,num_layers=2)\n",
    "\n",
    "\n",
    "def func_pi(S, is_training):\n",
    "    return {'logits': nn_pi(S)}\n",
    "\n",
    "\n",
    "def func_v(S, is_training):\n",
    "    return nn_v(S).reshape(-1)\n",
    "\n",
    "\n",
    "\n",
    "# def func_pi(S, is_training):\n",
    "#     logits = hk.Sequential((\n",
    "#         hk.Linear(16), jax.nn.relu,\n",
    "#         hk.Linear(16), jax.nn.relu,\n",
    "#         hk.Linear(16), jax.nn.relu,\n",
    "#         hk.Linear(env.action_space.n, w_init=jnp.zeros)\n",
    "#     ))\n",
    "#     return {'logits': logits(S)}\n",
    "\n",
    "\n",
    "\n",
    "# def func_v(S, is_training):\n",
    "#     value = hk.Sequential((\n",
    "#         hk.Linear(32), jax.nn.relu,\n",
    "#         hk.Linear(32), jax.nn.relu,\n",
    "#         hk.Linear(32), jax.nn.relu,\n",
    "#         hk.Linear(32), jax.nn.relu,\n",
    "#         hk.Linear(32), jax.nn.relu,\n",
    "#         hk.Linear(1, w_init=jnp.zeros), jnp.ravel\n",
    "#     ))\n",
    "#     return value(S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# these optimizers collect batches of grads before applying updates\n",
    "optimizer_v = optax.chain(optax.apply_every(k=32), optax.adam(0.002))\n",
    "optimizer_pi = optax.chain(optax.apply_every(k=32), optax.adam(0.001))\n",
    "\n",
    "\n",
    "# value function and its derived policy\n",
    "v = coax.V(func_v, env)\n",
    "pi = coax.Policy(func_pi, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 1,\tT: 12,\tG: 11,\tavg_r: 1,\tavg_G: 11,\tt: 11,\tdt: 781.796ms,\tSimpleTD/loss: 0.349,\tVanillaPG/loss: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 2,\tT: 71,\tG: 58,\tavg_r: 1,\tavg_G: 34.5,\tt: 58,\tdt: 27.695ms,\tSimpleTD/loss: 0.371,\tVanillaPG/loss: 0.974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 58.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 3,\tT: 95,\tG: 23,\tavg_r: 1,\tavg_G: 30.7,\tt: 23,\tdt: 29.031ms,\tSimpleTD/loss: 0.755,\tVanillaPG/loss: 0.838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 4,\tT: 126,\tG: 30,\tavg_r: 1,\tavg_G: 30.5,\tt: 30,\tdt: 32.820ms,\tSimpleTD/loss: 0.658,\tVanillaPG/loss: 0.631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 30.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 5,\tT: 142,\tG: 15,\tavg_r: 1,\tavg_G: 27.4,\tt: 15,\tdt: 32.072ms,\tSimpleTD/loss: 1.74,\tVanillaPG/loss: 0.397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 6,\tT: 155,\tG: 12,\tavg_r: 1,\tavg_G: 24.8,\tt: 12,\tdt: 32.732ms,\tSimpleTD/loss: 2.87,\tVanillaPG/loss: 0.232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 7,\tT: 174,\tG: 18,\tavg_r: 1,\tavg_G: 23.9,\tt: 18,\tdt: 32.518ms,\tSimpleTD/loss: 0.878,\tVanillaPG/loss: 0.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 8,\tT: 184,\tG: 9,\tavg_r: 1,\tavg_G: 22,\tt: 9,\tdt: 33.430ms,\tSimpleTD/loss: 1.02,\tVanillaPG/loss: 0.553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 9,\tT: 206,\tG: 21,\tavg_r: 1,\tavg_G: 21.9,\tt: 21,\tdt: 31.557ms,\tSimpleTD/loss: 0.5,\tVanillaPG/loss: 0.745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 10,\tT: 244,\tG: 37,\tavg_r: 1,\tavg_G: 23.4,\tt: 37,\tdt: 32.107ms,\tSimpleTD/loss: 0.422,\tVanillaPG/loss: 0.694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 37.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 11,\tT: 263,\tG: 18,\tavg_r: 1,\tavg_G: 22.9,\tt: 18,\tdt: 32.423ms,\tSimpleTD/loss: 0.467,\tVanillaPG/loss: 0.412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 12,\tT: 279,\tG: 15,\tavg_r: 1,\tavg_G: 22.1,\tt: 15,\tdt: 32.569ms,\tSimpleTD/loss: 0.153,\tVanillaPG/loss: 0.565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 13,\tT: 297,\tG: 17,\tavg_r: 1,\tavg_G: 21.6,\tt: 17,\tdt: 32.002ms,\tSimpleTD/loss: 0.508,\tVanillaPG/loss: 0.522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 14,\tT: 310,\tG: 12,\tavg_r: 1,\tavg_G: 20.6,\tt: 12,\tdt: 32.540ms,\tSimpleTD/loss: 0.934,\tVanillaPG/loss: 0.889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 15,\tT: 322,\tG: 11,\tavg_r: 1,\tavg_G: 19.6,\tt: 11,\tdt: 31.599ms,\tSimpleTD/loss: 7.49,\tVanillaPG/loss: 0.608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 16,\tT: 335,\tG: 12,\tavg_r: 1,\tavg_G: 18.9,\tt: 12,\tdt: 33.140ms,\tSimpleTD/loss: 13.1,\tVanillaPG/loss: 0.676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 17,\tT: 346,\tG: 10,\tavg_r: 1,\tavg_G: 18,\tt: 10,\tdt: 34.815ms,\tSimpleTD/loss: 0.282,\tVanillaPG/loss: 0.408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 18,\tT: 366,\tG: 19,\tavg_r: 1,\tavg_G: 18.1,\tt: 19,\tdt: 31.860ms,\tSimpleTD/loss: 0.517,\tVanillaPG/loss: 0.526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 19,\tT: 383,\tG: 16,\tavg_r: 1,\tavg_G: 17.9,\tt: 16,\tdt: 33.490ms,\tSimpleTD/loss: 0.716,\tVanillaPG/loss: 0.536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 20,\tT: 408,\tG: 24,\tavg_r: 1,\tavg_G: 18.5,\tt: 24,\tdt: 34.548ms,\tSimpleTD/loss: 0.256,\tVanillaPG/loss: 0.575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 21,\tT: 419,\tG: 10,\tavg_r: 1,\tavg_G: 17.6,\tt: 10,\tdt: 33.563ms,\tSimpleTD/loss: 1.27,\tVanillaPG/loss: 0.286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 22,\tT: 436,\tG: 16,\tavg_r: 1,\tavg_G: 17.5,\tt: 16,\tdt: 32.444ms,\tSimpleTD/loss: 1.34,\tVanillaPG/loss: 0.355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 23,\tT: 449,\tG: 12,\tavg_r: 1,\tavg_G: 16.9,\tt: 12,\tdt: 33.376ms,\tSimpleTD/loss: 0.236,\tVanillaPG/loss: 0.439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 24,\tT: 462,\tG: 12,\tavg_r: 1,\tavg_G: 16.4,\tt: 12,\tdt: 33.570ms,\tSimpleTD/loss: 0.399,\tVanillaPG/loss: 0.549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 25,\tT: 473,\tG: 10,\tavg_r: 1,\tavg_G: 15.8,\tt: 10,\tdt: 33.619ms,\tSimpleTD/loss: 0.517,\tVanillaPG/loss: 0.548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 26,\tT: 501,\tG: 27,\tavg_r: 1,\tavg_G: 16.9,\tt: 27,\tdt: 32.895ms,\tSimpleTD/loss: 0.213,\tVanillaPG/loss: 0.703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 27.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 27,\tT: 519,\tG: 17,\tavg_r: 1,\tavg_G: 16.9,\tt: 17,\tdt: 32.182ms,\tSimpleTD/loss: 0.387,\tVanillaPG/loss: 0.465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 28,\tT: 535,\tG: 15,\tavg_r: 1,\tavg_G: 16.7,\tt: 15,\tdt: 32.902ms,\tSimpleTD/loss: 0.711,\tVanillaPG/loss: 0.287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 29,\tT: 623,\tG: 87,\tavg_r: 1,\tavg_G: 23.8,\tt: 87,\tdt: 33.137ms,\tSimpleTD/loss: 0.61,\tVanillaPG/loss: 0.425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 87.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 30,\tT: 640,\tG: 16,\tavg_r: 1,\tavg_G: 23,\tt: 16,\tdt: 32.892ms,\tSimpleTD/loss: 1.81,\tVanillaPG/loss: 0.176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 31,\tT: 682,\tG: 41,\tavg_r: 1,\tavg_G: 24.8,\tt: 41,\tdt: 32.496ms,\tSimpleTD/loss: 0.379,\tVanillaPG/loss: 0.557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 41.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 32,\tT: 719,\tG: 36,\tavg_r: 1,\tavg_G: 25.9,\tt: 36,\tdt: 33.911ms,\tSimpleTD/loss: 0.589,\tVanillaPG/loss: 0.586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 36.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 33,\tT: 741,\tG: 21,\tavg_r: 1,\tavg_G: 25.4,\tt: 21,\tdt: 32.159ms,\tSimpleTD/loss: 0.755,\tVanillaPG/loss: 0.463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 34,\tT: 780,\tG: 38,\tavg_r: 1,\tavg_G: 26.7,\tt: 38,\tdt: 34.384ms,\tSimpleTD/loss: 0.63,\tVanillaPG/loss: 0.257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 38.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 35,\tT: 820,\tG: 39,\tavg_r: 1,\tavg_G: 27.9,\tt: 39,\tdt: 32.669ms,\tSimpleTD/loss: 0.616,\tVanillaPG/loss: 0.243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 39.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 36,\tT: 895,\tG: 74,\tavg_r: 1,\tavg_G: 32.5,\tt: 74,\tdt: 31.926ms,\tSimpleTD/loss: 0.58,\tVanillaPG/loss: 0.208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 74.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 37,\tT: 990,\tG: 94,\tavg_r: 1,\tavg_G: 38.7,\tt: 94,\tdt: 32.859ms,\tSimpleTD/loss: 0.522,\tVanillaPG/loss: 0.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 94.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 38,\tT: 1,070,\tG: 79,\tavg_r: 1,\tavg_G: 42.7,\tt: 79,\tdt: 33.031ms,\tSimpleTD/loss: 0.45,\tVanillaPG/loss: 0.531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 79.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 39,\tT: 1,168,\tG: 97,\tavg_r: 1,\tavg_G: 48.1,\tt: 97,\tdt: 32.873ms,\tSimpleTD/loss: 0.37,\tVanillaPG/loss: 0.493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 97.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 40,\tT: 1,215,\tG: 46,\tavg_r: 1,\tavg_G: 47.9,\tt: 46,\tdt: 32.414ms,\tSimpleTD/loss: 0.473,\tVanillaPG/loss: 0.488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 46.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 41,\tT: 1,271,\tG: 55,\tavg_r: 1,\tavg_G: 48.6,\tt: 55,\tdt: 32.727ms,\tSimpleTD/loss: 0.562,\tVanillaPG/loss: 0.542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 55.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 42,\tT: 1,373,\tG: 101,\tavg_r: 1,\tavg_G: 53.9,\tt: 101,\tdt: 32.076ms,\tSimpleTD/loss: 0.41,\tVanillaPG/loss: 0.513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 101.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 43,\tT: 1,459,\tG: 85,\tavg_r: 1,\tavg_G: 57,\tt: 85,\tdt: 32.906ms,\tSimpleTD/loss: 0.407,\tVanillaPG/loss: 0.518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 85.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 44,\tT: 1,517,\tG: 57,\tavg_r: 1,\tavg_G: 57,\tt: 57,\tdt: 32.785ms,\tSimpleTD/loss: 0.409,\tVanillaPG/loss: 0.456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 57.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 45,\tT: 1,609,\tG: 91,\tavg_r: 1,\tavg_G: 60.4,\tt: 91,\tdt: 32.846ms,\tSimpleTD/loss: 0.364,\tVanillaPG/loss: 0.523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 91.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 46,\tT: 1,682,\tG: 72,\tavg_r: 1,\tavg_G: 61.5,\tt: 72,\tdt: 32.691ms,\tSimpleTD/loss: 0.478,\tVanillaPG/loss: 0.353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 72.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 47,\tT: 1,727,\tG: 44,\tavg_r: 1,\tavg_G: 59.8,\tt: 44,\tdt: 32.194ms,\tSimpleTD/loss: 0.443,\tVanillaPG/loss: 0.479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 44.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 48,\tT: 1,798,\tG: 70,\tavg_r: 1,\tavg_G: 60.8,\tt: 70,\tdt: 32.459ms,\tSimpleTD/loss: 0.354,\tVanillaPG/loss: 0.527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 70.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 49,\tT: 1,860,\tG: 61,\tavg_r: 1,\tavg_G: 60.8,\tt: 61,\tdt: 32.318ms,\tSimpleTD/loss: 0.38,\tVanillaPG/loss: 0.486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 61.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 50,\tT: 1,936,\tG: 75,\tavg_r: 1,\tavg_G: 62.2,\tt: 75,\tdt: 32.248ms,\tSimpleTD/loss: 0.238,\tVanillaPG/loss: 0.517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 75.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 51,\tT: 1,990,\tG: 53,\tavg_r: 1,\tavg_G: 61.3,\tt: 53,\tdt: 32.103ms,\tSimpleTD/loss: 0.363,\tVanillaPG/loss: 0.403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 53.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 52,\tT: 2,090,\tG: 99,\tavg_r: 1,\tavg_G: 65.1,\tt: 99,\tdt: 32.539ms,\tSimpleTD/loss: 0.042,\tVanillaPG/loss: 0.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 99.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 53,\tT: 2,179,\tG: 88,\tavg_r: 1,\tavg_G: 67.4,\tt: 88,\tdt: 33.312ms,\tSimpleTD/loss: 0.0269,\tVanillaPG/loss: 0.487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 88.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 54,\tT: 2,255,\tG: 75,\tavg_r: 1,\tavg_G: 68.1,\tt: 75,\tdt: 32.101ms,\tSimpleTD/loss: 0.0442,\tVanillaPG/loss: 0.496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 75.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 55,\tT: 2,348,\tG: 92,\tavg_r: 1,\tavg_G: 70.5,\tt: 92,\tdt: 32.275ms,\tSimpleTD/loss: 0.0137,\tVanillaPG/loss: 0.509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 92.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 56,\tT: 2,416,\tG: 67,\tavg_r: 1,\tavg_G: 70.2,\tt: 67,\tdt: 32.982ms,\tSimpleTD/loss: 0.00824,\tVanillaPG/loss: 0.512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 67.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 57,\tT: 2,472,\tG: 55,\tavg_r: 1,\tavg_G: 68.7,\tt: 55,\tdt: 31.775ms,\tSimpleTD/loss: 0.008,\tVanillaPG/loss: 0.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 55.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 58,\tT: 2,550,\tG: 77,\tavg_r: 1,\tavg_G: 69.5,\tt: 77,\tdt: 32.824ms,\tSimpleTD/loss: 0.0273,\tVanillaPG/loss: 0.493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 77.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 59,\tT: 2,613,\tG: 62,\tavg_r: 1,\tavg_G: 68.7,\tt: 62,\tdt: 32.319ms,\tSimpleTD/loss: 0.0254,\tVanillaPG/loss: 0.494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 62.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 60,\tT: 2,669,\tG: 55,\tavg_r: 1,\tavg_G: 67.4,\tt: 55,\tdt: 32.414ms,\tSimpleTD/loss: 0.00634,\tVanillaPG/loss: 0.513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 55.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 61,\tT: 2,724,\tG: 54,\tavg_r: 1,\tavg_G: 66,\tt: 54,\tdt: 33.210ms,\tSimpleTD/loss: 0.0296,\tVanillaPG/loss: 0.506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 54.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 62,\tT: 2,779,\tG: 54,\tavg_r: 1,\tavg_G: 64.8,\tt: 54,\tdt: 32.184ms,\tSimpleTD/loss: 0.00894,\tVanillaPG/loss: 0.507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 54.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 63,\tT: 2,970,\tG: 190,\tavg_r: 1,\tavg_G: 77.3,\tt: 190,\tdt: 31.868ms,\tSimpleTD/loss: 0.00973,\tVanillaPG/loss: 0.512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 190.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 64,\tT: 3,062,\tG: 91,\tavg_r: 1,\tavg_G: 78.7,\tt: 91,\tdt: 32.944ms,\tSimpleTD/loss: 0.00532,\tVanillaPG/loss: 0.503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 91.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 65,\tT: 3,130,\tG: 67,\tavg_r: 1,\tavg_G: 77.5,\tt: 67,\tdt: 33.128ms,\tSimpleTD/loss: 0.0756,\tVanillaPG/loss: 0.508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 67.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 66,\tT: 3,186,\tG: 55,\tavg_r: 1,\tavg_G: 75.3,\tt: 55,\tdt: 31.742ms,\tSimpleTD/loss: 0.031,\tVanillaPG/loss: 0.508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 55.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 67,\tT: 3,283,\tG: 96,\tavg_r: 1,\tavg_G: 77.4,\tt: 96,\tdt: 32.374ms,\tSimpleTD/loss: 0.0135,\tVanillaPG/loss: 0.511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 96.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 68,\tT: 3,353,\tG: 69,\tavg_r: 1,\tavg_G: 76.5,\tt: 69,\tdt: 32.295ms,\tSimpleTD/loss: 0.102,\tVanillaPG/loss: 0.505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 69.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 69,\tT: 3,433,\tG: 79,\tavg_r: 1,\tavg_G: 76.8,\tt: 79,\tdt: 31.699ms,\tSimpleTD/loss: 0.0466,\tVanillaPG/loss: 0.491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 79.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 70,\tT: 3,524,\tG: 90,\tavg_r: 1,\tavg_G: 78.1,\tt: 90,\tdt: 32.349ms,\tSimpleTD/loss: 0.0321,\tVanillaPG/loss: 0.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 90.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 71,\tT: 3,643,\tG: 118,\tavg_r: 1,\tavg_G: 82.1,\tt: 118,\tdt: 31.840ms,\tSimpleTD/loss: 0.196,\tVanillaPG/loss: 0.509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 118.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 72,\tT: 3,785,\tG: 141,\tavg_r: 1,\tavg_G: 88,\tt: 141,\tdt: 32.174ms,\tSimpleTD/loss: 0.0143,\tVanillaPG/loss: 0.523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 141.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 73,\tT: 3,855,\tG: 69,\tavg_r: 1,\tavg_G: 86.1,\tt: 69,\tdt: 30.399ms,\tSimpleTD/loss: 0.282,\tVanillaPG/loss: 0.508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 69.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 74,\tT: 3,960,\tG: 104,\tavg_r: 1,\tavg_G: 87.9,\tt: 104,\tdt: 32.014ms,\tSimpleTD/loss: 0.154,\tVanillaPG/loss: 0.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 104.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 75,\tT: 4,042,\tG: 81,\tavg_r: 1,\tavg_G: 87.2,\tt: 81,\tdt: 32.220ms,\tSimpleTD/loss: 0.063,\tVanillaPG/loss: 0.514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 81.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 76,\tT: 4,156,\tG: 113,\tavg_r: 1,\tavg_G: 89.8,\tt: 113,\tdt: 32.458ms,\tSimpleTD/loss: 0.0291,\tVanillaPG/loss: 0.511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 113.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 77,\tT: 4,244,\tG: 87,\tavg_r: 1,\tavg_G: 89.5,\tt: 87,\tdt: 32.232ms,\tSimpleTD/loss: 0.046,\tVanillaPG/loss: 0.513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 87.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 78,\tT: 4,363,\tG: 118,\tavg_r: 1,\tavg_G: 92.3,\tt: 118,\tdt: 32.287ms,\tSimpleTD/loss: 0.0303,\tVanillaPG/loss: 0.517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 118.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 79,\tT: 4,462,\tG: 98,\tavg_r: 1,\tavg_G: 92.9,\tt: 98,\tdt: 32.298ms,\tSimpleTD/loss: 0.144,\tVanillaPG/loss: 0.512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 98.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 80,\tT: 4,579,\tG: 116,\tavg_r: 1,\tavg_G: 95.2,\tt: 116,\tdt: 32.232ms,\tSimpleTD/loss: 0.0507,\tVanillaPG/loss: 0.515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 116.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 81,\tT: 4,673,\tG: 93,\tavg_r: 1,\tavg_G: 95,\tt: 93,\tdt: 32.958ms,\tSimpleTD/loss: 0.169,\tVanillaPG/loss: 0.515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 93.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 82,\tT: 4,767,\tG: 93,\tavg_r: 1,\tavg_G: 94.8,\tt: 93,\tdt: 32.177ms,\tSimpleTD/loss: 0.0975,\tVanillaPG/loss: 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 93.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 83,\tT: 4,968,\tG: 200,\tavg_r: 1,\tavg_G: 105,\tt: 200,\tdt: 32.387ms,\tSimpleTD/loss: 0.00355,\tVanillaPG/loss: 0.515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 84,\tT: 5,063,\tG: 94,\tavg_r: 1,\tavg_G: 104,\tt: 94,\tdt: 32.087ms,\tSimpleTD/loss: 0.0248,\tVanillaPG/loss: 0.514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 94.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 85,\tT: 5,139,\tG: 75,\tavg_r: 1,\tavg_G: 101,\tt: 75,\tdt: 31.875ms,\tSimpleTD/loss: 0.384,\tVanillaPG/loss: 0.515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 75.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 86,\tT: 5,276,\tG: 136,\tavg_r: 1,\tavg_G: 105,\tt: 136,\tdt: 32.073ms,\tSimpleTD/loss: 0.123,\tVanillaPG/loss: 0.521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 136.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 87,\tT: 5,439,\tG: 162,\tavg_r: 1,\tavg_G: 110,\tt: 162,\tdt: 30.874ms,\tSimpleTD/loss: 0.293,\tVanillaPG/loss: 0.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 162.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 88,\tT: 5,509,\tG: 69,\tavg_r: 1,\tavg_G: 106,\tt: 69,\tdt: 32.926ms,\tSimpleTD/loss: 0.36,\tVanillaPG/loss: 0.521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 69.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 89,\tT: 5,571,\tG: 61,\tavg_r: 1,\tavg_G: 102,\tt: 61,\tdt: 32.088ms,\tSimpleTD/loss: 0.417,\tVanillaPG/loss: 0.521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 61.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 90,\tT: 5,649,\tG: 77,\tavg_r: 1,\tavg_G: 99.3,\tt: 77,\tdt: 31.544ms,\tSimpleTD/loss: 0.227,\tVanillaPG/loss: 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 77.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 91,\tT: 5,694,\tG: 44,\tavg_r: 1,\tavg_G: 93.8,\tt: 44,\tdt: 32.294ms,\tSimpleTD/loss: 0.45,\tVanillaPG/loss: 0.491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 44.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 92,\tT: 5,752,\tG: 57,\tavg_r: 1,\tavg_G: 90.1,\tt: 57,\tdt: 27.919ms,\tSimpleTD/loss: 0.161,\tVanillaPG/loss: 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 57.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 93,\tT: 5,816,\tG: 63,\tavg_r: 1,\tavg_G: 87.4,\tt: 63,\tdt: 31.665ms,\tSimpleTD/loss: 0.132,\tVanillaPG/loss: 0.512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 63.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 94,\tT: 5,884,\tG: 67,\tavg_r: 1,\tavg_G: 85.4,\tt: 67,\tdt: 32.821ms,\tSimpleTD/loss: 0.0419,\tVanillaPG/loss: 0.519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 67.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 95,\tT: 6,003,\tG: 118,\tavg_r: 1,\tavg_G: 88.6,\tt: 118,\tdt: 32.627ms,\tSimpleTD/loss: 0.0179,\tVanillaPG/loss: 0.517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 118.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 96,\tT: 6,075,\tG: 71,\tavg_r: 1,\tavg_G: 86.9,\tt: 71,\tdt: 32.158ms,\tSimpleTD/loss: 0.0289,\tVanillaPG/loss: 0.517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 71.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 97,\tT: 6,191,\tG: 115,\tavg_r: 1,\tavg_G: 89.7,\tt: 115,\tdt: 31.625ms,\tSimpleTD/loss: 0.000993,\tVanillaPG/loss: 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 115.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 98,\tT: 6,269,\tG: 77,\tavg_r: 1,\tavg_G: 88.4,\tt: 77,\tdt: 32.261ms,\tSimpleTD/loss: 0.00966,\tVanillaPG/loss: 0.503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 77.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 99,\tT: 6,334,\tG: 64,\tavg_r: 1,\tavg_G: 86,\tt: 64,\tdt: 31.304ms,\tSimpleTD/loss: 0.00669,\tVanillaPG/loss: 0.515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 64.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 100,\tT: 6,535,\tG: 200,\tavg_r: 1,\tavg_G: 97.4,\tt: 200,\tdt: 31.392ms,\tSimpleTD/loss: 0.000311,\tVanillaPG/loss: 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 101,\tT: 6,726,\tG: 190,\tavg_r: 1,\tavg_G: 107,\tt: 190,\tdt: 32.375ms,\tSimpleTD/loss: 0.0568,\tVanillaPG/loss: 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 190.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 102,\tT: 6,782,\tG: 55,\tavg_r: 1,\tavg_G: 101,\tt: 55,\tdt: 32.108ms,\tSimpleTD/loss: 0.00773,\tVanillaPG/loss: 0.518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 55.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 103,\tT: 6,983,\tG: 200,\tavg_r: 1,\tavg_G: 111,\tt: 200,\tdt: 29.822ms,\tSimpleTD/loss: 0.0211,\tVanillaPG/loss: 0.517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 104,\tT: 7,093,\tG: 109,\tavg_r: 1,\tavg_G: 111,\tt: 109,\tdt: 28.193ms,\tSimpleTD/loss: 0.0782,\tVanillaPG/loss: 0.517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 109.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 105,\tT: 7,180,\tG: 86,\tavg_r: 1,\tavg_G: 109,\tt: 86,\tdt: 27.800ms,\tSimpleTD/loss: 0.0129,\tVanillaPG/loss: 0.51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 86.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 106,\tT: 7,314,\tG: 133,\tavg_r: 1,\tavg_G: 111,\tt: 133,\tdt: 31.271ms,\tSimpleTD/loss: 0.0267,\tVanillaPG/loss: 0.515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 133.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 107,\tT: 7,385,\tG: 70,\tavg_r: 1,\tavg_G: 107,\tt: 70,\tdt: 32.685ms,\tSimpleTD/loss: 0.0327,\tVanillaPG/loss: 0.518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 70.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 108,\tT: 7,458,\tG: 72,\tavg_r: 1,\tavg_G: 103,\tt: 72,\tdt: 32.751ms,\tSimpleTD/loss: 0.296,\tVanillaPG/loss: 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 72.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 109,\tT: 7,605,\tG: 146,\tavg_r: 1,\tavg_G: 108,\tt: 146,\tdt: 32.741ms,\tSimpleTD/loss: 0.0228,\tVanillaPG/loss: 0.517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 146.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 110,\tT: 7,731,\tG: 125,\tavg_r: 1,\tavg_G: 109,\tt: 125,\tdt: 32.514ms,\tSimpleTD/loss: 0.0205,\tVanillaPG/loss: 0.514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 125.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 111,\tT: 7,852,\tG: 120,\tavg_r: 1,\tavg_G: 110,\tt: 120,\tdt: 32.058ms,\tSimpleTD/loss: 0.163,\tVanillaPG/loss: 0.517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 120.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 112,\tT: 7,916,\tG: 63,\tavg_r: 1,\tavg_G: 106,\tt: 63,\tdt: 33.083ms,\tSimpleTD/loss: 0.0684,\tVanillaPG/loss: 0.517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 63.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 113,\tT: 7,984,\tG: 67,\tavg_r: 1,\tavg_G: 102,\tt: 67,\tdt: 32.664ms,\tSimpleTD/loss: 0.0199,\tVanillaPG/loss: 0.527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 67.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 114,\tT: 8,160,\tG: 175,\tavg_r: 1,\tavg_G: 109,\tt: 175,\tdt: 32.588ms,\tSimpleTD/loss: 0.0051,\tVanillaPG/loss: 0.517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 175.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 115,\tT: 8,337,\tG: 176,\tavg_r: 1,\tavg_G: 116,\tt: 176,\tdt: 31.733ms,\tSimpleTD/loss: 0.0285,\tVanillaPG/loss: 0.517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 176.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 116,\tT: 8,521,\tG: 183,\tavg_r: 1,\tavg_G: 123,\tt: 183,\tdt: 32.438ms,\tSimpleTD/loss: 0.00384,\tVanillaPG/loss: 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 183.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 117,\tT: 8,606,\tG: 84,\tavg_r: 1,\tavg_G: 119,\tt: 84,\tdt: 32.266ms,\tSimpleTD/loss: 0.106,\tVanillaPG/loss: 0.515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 84.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 118,\tT: 8,727,\tG: 120,\tavg_r: 1,\tavg_G: 119,\tt: 120,\tdt: 31.630ms,\tSimpleTD/loss: 0.0267,\tVanillaPG/loss: 0.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 120.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 119,\tT: 8,845,\tG: 117,\tavg_r: 1,\tavg_G: 119,\tt: 117,\tdt: 31.335ms,\tSimpleTD/loss: 0.117,\tVanillaPG/loss: 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 117.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 120,\tT: 8,994,\tG: 148,\tavg_r: 1,\tavg_G: 122,\tt: 148,\tdt: 27.795ms,\tSimpleTD/loss: 0.0333,\tVanillaPG/loss: 0.517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 148.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 121,\tT: 9,106,\tG: 111,\tavg_r: 1,\tavg_G: 121,\tt: 111,\tdt: 31.457ms,\tSimpleTD/loss: 0.0196,\tVanillaPG/loss: 0.517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 111.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 122,\tT: 9,200,\tG: 93,\tavg_r: 1,\tavg_G: 118,\tt: 93,\tdt: 32.024ms,\tSimpleTD/loss: 0.137,\tVanillaPG/loss: 0.517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 93.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 123,\tT: 9,349,\tG: 148,\tavg_r: 1,\tavg_G: 121,\tt: 148,\tdt: 31.956ms,\tSimpleTD/loss: 0.0178,\tVanillaPG/loss: 0.512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 148.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 124,\tT: 9,550,\tG: 200,\tavg_r: 1,\tavg_G: 129,\tt: 200,\tdt: 32.403ms,\tSimpleTD/loss: 0.000969,\tVanillaPG/loss: 0.517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 125,\tT: 9,712,\tG: 161,\tavg_r: 1,\tavg_G: 132,\tt: 161,\tdt: 32.308ms,\tSimpleTD/loss: 0.1,\tVanillaPG/loss: 0.518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 161.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 126,\tT: 9,913,\tG: 200,\tavg_r: 1,\tavg_G: 139,\tt: 200,\tdt: 32.427ms,\tSimpleTD/loss: 0.0331,\tVanillaPG/loss: 0.563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 127,\tT: 10,114,\tG: 200,\tavg_r: 1,\tavg_G: 145,\tt: 200,\tdt: 31.035ms,\tSimpleTD/loss: 0.0111,\tVanillaPG/loss: 0.511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 128,\tT: 10,315,\tG: 200,\tavg_r: 1,\tavg_G: 150,\tt: 200,\tdt: 29.520ms,\tSimpleTD/loss: 0.000332,\tVanillaPG/loss: 0.515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 129,\tT: 10,516,\tG: 200,\tavg_r: 1,\tavg_G: 155,\tt: 200,\tdt: 29.264ms,\tSimpleTD/loss: 6.81e-06,\tVanillaPG/loss: 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 130,\tT: 10,717,\tG: 200,\tavg_r: 1,\tavg_G: 160,\tt: 200,\tdt: 30.888ms,\tSimpleTD/loss: 4.27e-06,\tVanillaPG/loss: 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 131,\tT: 10,918,\tG: 200,\tavg_r: 1,\tavg_G: 164,\tt: 200,\tdt: 30.620ms,\tSimpleTD/loss: 3.99e-06,\tVanillaPG/loss: 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 132,\tT: 11,119,\tG: 200,\tavg_r: 1,\tavg_G: 167,\tt: 200,\tdt: 30.457ms,\tSimpleTD/loss: 4.39e-06,\tVanillaPG/loss: 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 133,\tT: 11,320,\tG: 200,\tavg_r: 1,\tavg_G: 171,\tt: 200,\tdt: 29.840ms,\tSimpleTD/loss: 4.26e-06,\tVanillaPG/loss: 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 134,\tT: 11,521,\tG: 200,\tavg_r: 1,\tavg_G: 174,\tt: 200,\tdt: 29.856ms,\tSimpleTD/loss: 5.05e-06,\tVanillaPG/loss: 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 135,\tT: 11,722,\tG: 200,\tavg_r: 1,\tavg_G: 176,\tt: 200,\tdt: 32.319ms,\tSimpleTD/loss: 3.77e-06,\tVanillaPG/loss: 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 136,\tT: 11,923,\tG: 200,\tavg_r: 1,\tavg_G: 179,\tt: 200,\tdt: 31.674ms,\tSimpleTD/loss: 3.7e-06,\tVanillaPG/loss: 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 137,\tT: 12,124,\tG: 200,\tavg_r: 1,\tavg_G: 181,\tt: 200,\tdt: 31.746ms,\tSimpleTD/loss: 4.83e-06,\tVanillaPG/loss: 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 138,\tT: 12,325,\tG: 200,\tavg_r: 1,\tavg_G: 183,\tt: 200,\tdt: 30.411ms,\tSimpleTD/loss: 6.98e-05,\tVanillaPG/loss: 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 139,\tT: 12,526,\tG: 200,\tavg_r: 1,\tavg_G: 184,\tt: 200,\tdt: 32.387ms,\tSimpleTD/loss: 0.000834,\tVanillaPG/loss: 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 140,\tT: 12,727,\tG: 200,\tavg_r: 1,\tavg_G: 186,\tt: 200,\tdt: 32.248ms,\tSimpleTD/loss: 0.000214,\tVanillaPG/loss: 0.517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 141,\tT: 12,928,\tG: 200,\tavg_r: 1,\tavg_G: 187,\tt: 200,\tdt: 31.847ms,\tSimpleTD/loss: 5.91e-05,\tVanillaPG/loss: 0.515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 142,\tT: 13,129,\tG: 200,\tavg_r: 1,\tavg_G: 189,\tt: 200,\tdt: 32.620ms,\tSimpleTD/loss: 0.000118,\tVanillaPG/loss: 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 143,\tT: 13,330,\tG: 200,\tavg_r: 1,\tavg_G: 190,\tt: 200,\tdt: 30.155ms,\tSimpleTD/loss: 0.000139,\tVanillaPG/loss: 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 144,\tT: 13,531,\tG: 200,\tavg_r: 1,\tavg_G: 191,\tt: 200,\tdt: 27.240ms,\tSimpleTD/loss: 0.000122,\tVanillaPG/loss: 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 145,\tT: 13,732,\tG: 200,\tavg_r: 1,\tavg_G: 192,\tt: 200,\tdt: 29.924ms,\tSimpleTD/loss: 0.000192,\tVanillaPG/loss: 0.515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 146,\tT: 13,933,\tG: 200,\tavg_r: 1,\tavg_G: 193,\tt: 200,\tdt: 32.106ms,\tSimpleTD/loss: 0.000489,\tVanillaPG/loss: 0.515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 147,\tT: 14,134,\tG: 200,\tavg_r: 1,\tavg_G: 193,\tt: 200,\tdt: 29.369ms,\tSimpleTD/loss: 0.000495,\tVanillaPG/loss: 0.518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 148,\tT: 14,335,\tG: 200,\tavg_r: 1,\tavg_G: 194,\tt: 200,\tdt: 31.016ms,\tSimpleTD/loss: 0.00026,\tVanillaPG/loss: 0.515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 149,\tT: 14,536,\tG: 200,\tavg_r: 1,\tavg_G: 195,\tt: 200,\tdt: 28.119ms,\tSimpleTD/loss: 0.000225,\tVanillaPG/loss: 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n",
      "Epoch reward 209.0\n"
     ]
    }
   ],
   "source": [
    "# experience tracer\n",
    "pi_regularizer = RPPRegularizer(pi, basic_wd=1e-4, equiv_wd=1e-4)\n",
    "tracer = coax.reward_tracing.NStep(n=1, gamma=0.9)\n",
    "\n",
    "# updaters\n",
    "vanilla_pg = coax.policy_objectives.VanillaPG(pi, optimizer=optimizer_pi,\n",
    "                                              regularizer=pi_regularizer)\n",
    "simple_td = coax.td_learning.SimpleTD(v, loss_function=mse, optimizer=optimizer_v)\n",
    "\n",
    "epoch_rewards = []\n",
    "\n",
    "# train\n",
    "for ep in range(1000):\n",
    "    s = env.reset()\n",
    "    er = 0\n",
    "    for t in range(env.spec.max_episode_steps):\n",
    "        a = pi(s)\n",
    "        s_next, r, done, info = env.step(a)\n",
    "        \n",
    "        if done and (t == env.spec.max_episode_steps - 1):\n",
    "            r = 1 / (1 - tracer.gamma)\n",
    "        er+=r\n",
    "        tracer.add(s, a, r, done)\n",
    "        while tracer:\n",
    "            transition_batch = tracer.pop()\n",
    "            metrics_v, td_error = simple_td.update(transition_batch, return_td_error=True)\n",
    "            metrics_pi = vanilla_pg.update(transition_batch, td_error)\n",
    "            env.record_metrics(metrics_v)\n",
    "            env.record_metrics(metrics_pi)\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        s = s_next\n",
    "    \n",
    "    print(\"Epoch reward\",er)\n",
    "    epoch_rewards.append(er)\n",
    "    # early stopping\n",
    "    if env.avg_G > env.spec.reward_threshold:\n",
    "        break\n",
    "\n",
    "\n",
    "# run env one more time to render\n",
    "#coax.utils.generate_gif(env, policy=pi, filepath=f\"./data/{name}.gif\", duration=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RPPRegularizer/basic_l2': DeviceArray(0., dtype=float32),\n",
       " 'RPPRegularizer/basic_wd': DeviceArray(1.e-04, dtype=float32),\n",
       " 'RPPRegularizer/equiv_l2': DeviceArray(5165.331, dtype=float32),\n",
       " 'RPPRegularizer/equiv_wd': DeviceArray(1.e-04, dtype=float32),\n",
       " 'VanillaPG/grads_max': DeviceArray(0.08917519, dtype=float32),\n",
       " 'VanillaPG/grads_norm': DeviceArray(0.48706943, dtype=float32),\n",
       " 'VanillaPG/kl_div_old': DeviceArray(0.23434481, dtype=float32),\n",
       " 'VanillaPG/loss': DeviceArray(0.48180765, dtype=float32),\n",
       " 'VanillaPG/loss_bare': DeviceArray(-0.03472544, dtype=float32)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eq l2 =  338.9434\n",
      "Basic l2 =  0.0\n"
     ]
    }
   ],
   "source": [
    "equiv_l2 = 0.0\n",
    "basic_l2 = 0.0\n",
    "for k1, v1 in pi.params.items():\n",
    "    if \"bi\" not in k1:\n",
    "        for k2, v2 in v1.items():\n",
    "    #         if \"bi\" not in k2:\n",
    "    #             print(k2)\n",
    "            if k2.endswith(\"_basic\"):\n",
    "                basic_l2 += (v2 ** 2).sum()\n",
    "            elif k2.endswith(\"w\"):\n",
    "                equiv_l2 += (v2 ** 2).sum()\n",
    "print(\"Eq l2 = \", equiv_l2)\n",
    "print(\"Basic l2 = \", basic_l2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
