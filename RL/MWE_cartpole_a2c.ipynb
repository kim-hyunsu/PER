{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coax\n",
    "import gym\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from coax.value_losses import mse\n",
    "\n",
    "\n",
    "\n",
    "# the name of this script\n",
    "name = 'a2c'\n",
    "\n",
    "# the cart-pole MDP\n",
    "env = gym.make('CartPole-v0')\n",
    "env = coax.wrappers.TrainMonitor(env, name=name, tensorboard_dir=f\"./data/tensorboard/{name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Baseline MLPS\n",
    "\n",
    "# def func_pi(S, is_training):\n",
    "#     logits = hk.Sequential((\n",
    "#         hk.Linear(8), jax.nn.relu,\n",
    "#         hk.Linear(8), jax.nn.relu,\n",
    "#         hk.Linear(8), jax.nn.relu,\n",
    "#         hk.Linear(env.action_space.n, w_init=jnp.zeros)\n",
    "#     ))\n",
    "#     return {'logits': logits(S)}\n",
    "\n",
    "\n",
    "# def func_v(S, is_training):\n",
    "#     value = hk.Sequential((\n",
    "#         hk.Linear(8), jax.nn.relu,\n",
    "#         hk.Linear(8), jax.nn.relu,\n",
    "#         hk.Linear(8), jax.nn.relu,\n",
    "#         hk.Linear(1, w_init=jnp.zeros), jnp.ravel\n",
    "#     ))\n",
    "#     return value(S)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|root|INFO] Initing EMLP\n",
      "[a2c|root|INFO] Linear W components:400 rep:96P+48P⊗V+20P⊗V²+8P⊗V³+4P⊗V⁴\n",
      "[a2c|root|INFO] P cache miss\n",
      "[a2c|root|INFO] Solving basis for P, for G=Z(2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(P+P+P+P) (P+P) 4P 2P\n",
      "[4P, 24V⁰+12V+5V²+2V³+V⁴, 24V⁰+12V+5V²+2V³+V⁴]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|root|INFO] P⊗V cache miss\n",
      "[a2c|root|INFO] Solving basis for P⊗V, for G=Z(2)\n",
      "[a2c|root|INFO] P⊗V² cache miss\n",
      "[a2c|root|INFO] Solving basis for P⊗V², for G=Z(2)\n",
      "[a2c|root|INFO] P⊗V³ cache miss\n",
      "[a2c|root|INFO] Solving basis for P⊗V³, for G=Z(2)\n",
      "[a2c|root|INFO] P⊗V⁴ cache miss\n",
      "[a2c|root|INFO] Solving basis for P⊗V⁴, for G=Z(2)\n",
      "[a2c|root|INFO] V cache miss\n",
      "[a2c|root|INFO] Solving basis for V, for G=Z(2)\n",
      "[a2c|root|INFO] V² cache miss\n",
      "[a2c|root|INFO] Solving basis for V², for G=Z(2)\n",
      "[a2c|root|INFO] V³ cache miss\n",
      "[a2c|root|INFO] Solving basis for V³, for G=Z(2)\n",
      "[a2c|root|INFO] V⁴ cache miss\n",
      "[a2c|root|INFO] Solving basis for V⁴, for G=Z(2)\n",
      "[a2c|root|INFO] Linear W components:10000 rep:576V⁰+576V+384V²+216V³+121V⁴+44V⁵+14V⁶+4V⁷+V⁸\n",
      "[a2c|root|INFO] V⁵ cache miss\n",
      "[a2c|root|INFO] Solving basis for V⁵, for G=Z(2)\n",
      "[a2c|root|INFO] V⁶ cache miss\n",
      "[a2c|root|INFO] Solving basis for V⁶, for G=Z(2)\n",
      "[a2c|root|INFO] V⁷ cache miss\n",
      "[a2c|root|INFO] Solving basis for V⁷, for G=Z(2)\n",
      "[a2c|root|INFO] V⁸ cache miss\n",
      "[a2c|root|INFO] Solving basis for V⁸, for G=Z(2)\n",
      "[a2c|root|INFO] Linear W components:200 rep:48P+24P⊗V+10P⊗V²+4P⊗V³+2P⊗V⁴\n",
      "[a2c|root|INFO] Initing EMLP\n",
      "[a2c|root|INFO] Linear W components:400 rep:96P+48P⊗V+20P⊗V²+8P⊗V³+4P⊗V⁴\n",
      "[a2c|root|INFO] Linear W components:10000 rep:576V⁰+576V+384V²+216V³+121V⁴+44V⁵+14V⁶+4V⁷+V⁸\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4P, 24V⁰+12V+5V²+2V³+V⁴, 24V⁰+12V+5V²+2V³+V⁴]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|root|INFO] Linear W components:100 rep:24V⁰+12V+5V²+2V³+V⁴\n"
     ]
    }
   ],
   "source": [
    "from emlp import T, Scalar\n",
    "from emlp.groups import SO, S, O, Trivial,Z\n",
    "from emlp_haiku import EMLPBlock, Sequential, Linear,EMLP\n",
    "from emlp.reps import Rep\n",
    "from emlp.nn import gated,gate_indices,uniform_rep\n",
    "from math import prod\n",
    "from representations import PseudoScalar\n",
    "\n",
    "## Trivial\n",
    "# group=Trivial(2)\n",
    "# rep_in = T(0)*prod(env.observation_space.shape)\n",
    "# rep_out = T(0)*env.action_space.n#prod(env.action_space.shape)\n",
    "\n",
    "## Reflection\n",
    "group=Z(2)\n",
    "rep_in = PseudoScalar()*prod(env.observation_space.shape)\n",
    "rep_out = PseudoScalar()*env.action_space.n#prod(env.action_space.shape)\n",
    "\n",
    "nn_pi = EMLP(rep_in,rep_out,group,ch=100,num_layers=2)\n",
    "nn_v = EMLP(rep_in,T(0),group,ch=100,num_layers=2)\n",
    "\n",
    "def func_pi(S, is_training):\n",
    "    return {'logits': nn_pi(S)}\n",
    "\n",
    "\n",
    "def func_v(S, is_training):\n",
    "    return nn_v(S).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 1,\tT: 28,\tG: 27,\tavg_r: 1,\tavg_G: 27,\tt: 27,\tdt: 309.307ms,\tSimpleTD/loss: 0.469,\tVanillaPG/loss: 0.665\n",
      "[a2c|TrainMonitor|INFO] ep: 2,\tT: 40,\tG: 11,\tavg_r: 1,\tavg_G: 19,\tt: 11,\tdt: 13.902ms,\tSimpleTD/loss: 0.419,\tVanillaPG/loss: 0.616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 27.0\n",
      "Epoch reward 11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 3,\tT: 56,\tG: 15,\tavg_r: 1,\tavg_G: 17.7,\tt: 15,\tdt: 14.357ms,\tSimpleTD/loss: 0.366,\tVanillaPG/loss: 0.532\n",
      "[a2c|TrainMonitor|INFO] ep: 4,\tT: 69,\tG: 12,\tavg_r: 1,\tavg_G: 16.2,\tt: 12,\tdt: 13.843ms,\tSimpleTD/loss: 0.356,\tVanillaPG/loss: 0.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 15.0\n",
      "Epoch reward 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 5,\tT: 91,\tG: 21,\tavg_r: 1,\tavg_G: 17.2,\tt: 21,\tdt: 14.643ms,\tSimpleTD/loss: 0.369,\tVanillaPG/loss: 0.406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 6,\tT: 111,\tG: 19,\tavg_r: 1,\tavg_G: 17.5,\tt: 19,\tdt: 14.556ms,\tSimpleTD/loss: 0.6,\tVanillaPG/loss: 0.324\n",
      "[a2c|TrainMonitor|INFO] ep: 7,\tT: 125,\tG: 13,\tavg_r: 1,\tavg_G: 16.9,\tt: 13,\tdt: 14.332ms,\tSimpleTD/loss: 0.955,\tVanillaPG/loss: 0.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 19.0\n",
      "Epoch reward 13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 8,\tT: 148,\tG: 22,\tavg_r: 1,\tavg_G: 17.5,\tt: 22,\tdt: 14.437ms,\tSimpleTD/loss: 0.907,\tVanillaPG/loss: 0.102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 9,\tT: 170,\tG: 21,\tavg_r: 1,\tavg_G: 17.9,\tt: 21,\tdt: 14.138ms,\tSimpleTD/loss: 1.01,\tVanillaPG/loss: -0.0192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 10,\tT: 212,\tG: 41,\tavg_r: 1,\tavg_G: 20.2,\tt: 41,\tdt: 13.915ms,\tSimpleTD/loss: 0.607,\tVanillaPG/loss: -0.037\n",
      "[a2c|TrainMonitor|INFO] ep: 11,\tT: 226,\tG: 13,\tavg_r: 1,\tavg_G: 19.5,\tt: 13,\tdt: 14.438ms,\tSimpleTD/loss: 1.98,\tVanillaPG/loss: -0.286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 41.0\n",
      "Epoch reward 13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 12,\tT: 238,\tG: 11,\tavg_r: 1,\tavg_G: 18.6,\tt: 11,\tdt: 14.084ms,\tSimpleTD/loss: 1.87,\tVanillaPG/loss: -0.288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 13,\tT: 256,\tG: 17,\tavg_r: 1,\tavg_G: 18.5,\tt: 17,\tdt: 13.978ms,\tSimpleTD/loss: 0.322,\tVanillaPG/loss: 0.168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 14,\tT: 288,\tG: 31,\tavg_r: 1,\tavg_G: 19.7,\tt: 31,\tdt: 14.516ms,\tSimpleTD/loss: 0.252,\tVanillaPG/loss: 0.261\n",
      "[a2c|TrainMonitor|INFO] ep: 15,\tT: 301,\tG: 12,\tavg_r: 1,\tavg_G: 18.9,\tt: 12,\tdt: 13.908ms,\tSimpleTD/loss: 0.479,\tVanillaPG/loss: 0.129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 31.0\n",
      "Epoch reward 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 16,\tT: 316,\tG: 14,\tavg_r: 1,\tavg_G: 18.5,\tt: 14,\tdt: 13.631ms,\tSimpleTD/loss: 0.574,\tVanillaPG/loss: 0.0389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 17,\tT: 333,\tG: 16,\tavg_r: 1,\tavg_G: 18.2,\tt: 16,\tdt: 13.432ms,\tSimpleTD/loss: 0.985,\tVanillaPG/loss: -0.0252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 18,\tT: 351,\tG: 17,\tavg_r: 1,\tavg_G: 18.1,\tt: 17,\tdt: 13.755ms,\tSimpleTD/loss: 0.324,\tVanillaPG/loss: -0.0265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 19,\tT: 371,\tG: 19,\tavg_r: 1,\tavg_G: 18.2,\tt: 19,\tdt: 13.945ms,\tSimpleTD/loss: 0.843,\tVanillaPG/loss: -0.0178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 20,\tT: 388,\tG: 16,\tavg_r: 1,\tavg_G: 18,\tt: 16,\tdt: 13.895ms,\tSimpleTD/loss: 0.361,\tVanillaPG/loss: 0.0253\n",
      "[a2c|TrainMonitor|INFO] ep: 21,\tT: 399,\tG: 10,\tavg_r: 1,\tavg_G: 17.2,\tt: 10,\tdt: 14.116ms,\tSimpleTD/loss: 1,\tVanillaPG/loss: -0.129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 16.0\n",
      "Epoch reward 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 22,\tT: 419,\tG: 19,\tavg_r: 1,\tavg_G: 17.3,\tt: 19,\tdt: 14.589ms,\tSimpleTD/loss: 0.36,\tVanillaPG/loss: 0.0111\n",
      "[a2c|TrainMonitor|INFO] ep: 23,\tT: 432,\tG: 12,\tavg_r: 1,\tavg_G: 16.8,\tt: 12,\tdt: 14.581ms,\tSimpleTD/loss: 0.359,\tVanillaPG/loss: 0.00218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 19.0\n",
      "Epoch reward 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 24,\tT: 446,\tG: 13,\tavg_r: 1,\tavg_G: 16.4,\tt: 13,\tdt: 15.539ms,\tSimpleTD/loss: 0.352,\tVanillaPG/loss: -0.132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 25,\tT: 481,\tG: 34,\tavg_r: 1,\tavg_G: 18.2,\tt: 34,\tdt: 14.542ms,\tSimpleTD/loss: 1.15,\tVanillaPG/loss: -0.0677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 34.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 26,\tT: 511,\tG: 29,\tavg_r: 1,\tavg_G: 19.3,\tt: 29,\tdt: 14.068ms,\tSimpleTD/loss: 0.943,\tVanillaPG/loss: -0.198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 29.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 27,\tT: 534,\tG: 22,\tavg_r: 1,\tavg_G: 19.5,\tt: 22,\tdt: 13.941ms,\tSimpleTD/loss: 0.457,\tVanillaPG/loss: 0.0267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 28,\tT: 613,\tG: 78,\tavg_r: 1,\tavg_G: 25.4,\tt: 78,\tdt: 13.854ms,\tSimpleTD/loss: 0.641,\tVanillaPG/loss: 0.133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 78.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 29,\tT: 634,\tG: 20,\tavg_r: 1,\tavg_G: 24.9,\tt: 20,\tdt: 13.554ms,\tSimpleTD/loss: 2.48,\tVanillaPG/loss: -0.997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 30,\tT: 676,\tG: 41,\tavg_r: 1,\tavg_G: 26.5,\tt: 41,\tdt: 14.745ms,\tSimpleTD/loss: 0.32,\tVanillaPG/loss: -0.0461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 41.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 31,\tT: 754,\tG: 77,\tavg_r: 1,\tavg_G: 31.5,\tt: 77,\tdt: 14.414ms,\tSimpleTD/loss: 0.54,\tVanillaPG/loss: 0.0462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 77.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 32,\tT: 863,\tG: 108,\tavg_r: 1,\tavg_G: 39.2,\tt: 108,\tdt: 14.179ms,\tSimpleTD/loss: 0.385,\tVanillaPG/loss: -0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 108.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 33,\tT: 929,\tG: 65,\tavg_r: 1,\tavg_G: 41.8,\tt: 65,\tdt: 14.331ms,\tSimpleTD/loss: 0.454,\tVanillaPG/loss: 0.00854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 65.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 34,\tT: 998,\tG: 68,\tavg_r: 1,\tavg_G: 44.4,\tt: 68,\tdt: 14.193ms,\tSimpleTD/loss: 0.543,\tVanillaPG/loss: -0.0493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 68.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 35,\tT: 1,106,\tG: 107,\tavg_r: 1,\tavg_G: 50.6,\tt: 107,\tdt: 14.096ms,\tSimpleTD/loss: 0.33,\tVanillaPG/loss: -0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 107.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 36,\tT: 1,257,\tG: 150,\tavg_r: 1,\tavg_G: 60.6,\tt: 150,\tdt: 14.057ms,\tSimpleTD/loss: 0.239,\tVanillaPG/loss: -0.0279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 150.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 37,\tT: 1,435,\tG: 177,\tavg_r: 1,\tavg_G: 72.2,\tt: 177,\tdt: 14.154ms,\tSimpleTD/loss: 0.184,\tVanillaPG/loss: 0.00619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 177.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 38,\tT: 1,571,\tG: 135,\tavg_r: 1,\tavg_G: 78.5,\tt: 135,\tdt: 14.134ms,\tSimpleTD/loss: 0.202,\tVanillaPG/loss: -0.0416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 135.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 39,\tT: 1,674,\tG: 102,\tavg_r: 1,\tavg_G: 80.8,\tt: 102,\tdt: 14.141ms,\tSimpleTD/loss: 0.244,\tVanillaPG/loss: -0.0152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 102.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 40,\tT: 1,752,\tG: 77,\tavg_r: 1,\tavg_G: 80.5,\tt: 77,\tdt: 13.875ms,\tSimpleTD/loss: 0.168,\tVanillaPG/loss: 0.000549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 77.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 41,\tT: 1,860,\tG: 107,\tavg_r: 1,\tavg_G: 83.1,\tt: 107,\tdt: 14.157ms,\tSimpleTD/loss: 0.0803,\tVanillaPG/loss: -0.0309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 107.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 42,\tT: 1,997,\tG: 136,\tavg_r: 1,\tavg_G: 88.4,\tt: 136,\tdt: 13.943ms,\tSimpleTD/loss: 0.281,\tVanillaPG/loss: -0.0713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 136.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 43,\tT: 2,198,\tG: 200,\tavg_r: 1,\tavg_G: 99.6,\tt: 200,\tdt: 13.784ms,\tSimpleTD/loss: 0.0574,\tVanillaPG/loss: -0.0167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 44,\tT: 2,262,\tG: 63,\tavg_r: 1,\tavg_G: 95.9,\tt: 63,\tdt: 14.394ms,\tSimpleTD/loss: 0.458,\tVanillaPG/loss: -0.0154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 63.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 45,\tT: 2,349,\tG: 86,\tavg_r: 1,\tavg_G: 94.9,\tt: 86,\tdt: 13.678ms,\tSimpleTD/loss: 0.261,\tVanillaPG/loss: 0.00405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 86.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 46,\tT: 2,456,\tG: 106,\tavg_r: 1,\tavg_G: 96,\tt: 106,\tdt: 14.411ms,\tSimpleTD/loss: 0.245,\tVanillaPG/loss: -0.00967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 106.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 47,\tT: 2,657,\tG: 200,\tavg_r: 1,\tavg_G: 106,\tt: 200,\tdt: 14.191ms,\tSimpleTD/loss: 0.0024,\tVanillaPG/loss: -0.0072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 48,\tT: 2,824,\tG: 166,\tavg_r: 1,\tavg_G: 112,\tt: 166,\tdt: 14.247ms,\tSimpleTD/loss: 0.105,\tVanillaPG/loss: -0.00813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 166.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 49,\tT: 2,908,\tG: 83,\tavg_r: 1,\tavg_G: 109,\tt: 83,\tdt: 14.234ms,\tSimpleTD/loss: 0.205,\tVanillaPG/loss: 0.00275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 83.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 50,\tT: 3,109,\tG: 200,\tavg_r: 1,\tavg_G: 118,\tt: 200,\tdt: 14.195ms,\tSimpleTD/loss: 0.0027,\tVanillaPG/loss: -0.00708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 51,\tT: 3,214,\tG: 104,\tavg_r: 1,\tavg_G: 117,\tt: 104,\tdt: 14.211ms,\tSimpleTD/loss: 0.0841,\tVanillaPG/loss: 0.000642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 104.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 52,\tT: 3,415,\tG: 200,\tavg_r: 1,\tavg_G: 125,\tt: 200,\tdt: 14.221ms,\tSimpleTD/loss: 0.00152,\tVanillaPG/loss: -0.0111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 53,\tT: 3,569,\tG: 153,\tavg_r: 1,\tavg_G: 128,\tt: 153,\tdt: 14.265ms,\tSimpleTD/loss: 0.0134,\tVanillaPG/loss: 0.00169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 153.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 54,\tT: 3,770,\tG: 200,\tavg_r: 1,\tavg_G: 135,\tt: 200,\tdt: 14.178ms,\tSimpleTD/loss: 0.00592,\tVanillaPG/loss: 0.00119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 55,\tT: 3,971,\tG: 200,\tavg_r: 1,\tavg_G: 142,\tt: 200,\tdt: 14.319ms,\tSimpleTD/loss: 0.000301,\tVanillaPG/loss: -0.00436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 56,\tT: 4,172,\tG: 200,\tavg_r: 1,\tavg_G: 148,\tt: 200,\tdt: 14.259ms,\tSimpleTD/loss: 0.000303,\tVanillaPG/loss: -0.00525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 57,\tT: 4,373,\tG: 200,\tavg_r: 1,\tavg_G: 153,\tt: 200,\tdt: 14.304ms,\tSimpleTD/loss: 0.000292,\tVanillaPG/loss: -0.00549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 58,\tT: 4,574,\tG: 200,\tavg_r: 1,\tavg_G: 158,\tt: 200,\tdt: 13.903ms,\tSimpleTD/loss: 0.000366,\tVanillaPG/loss: -0.00666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 59,\tT: 4,748,\tG: 173,\tavg_r: 1,\tavg_G: 159,\tt: 173,\tdt: 14.352ms,\tSimpleTD/loss: 0.115,\tVanillaPG/loss: 0.000649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 173.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 60,\tT: 4,918,\tG: 169,\tavg_r: 1,\tavg_G: 160,\tt: 169,\tdt: 14.323ms,\tSimpleTD/loss: 0.029,\tVanillaPG/loss: 0.00335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 169.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 61,\tT: 5,119,\tG: 200,\tavg_r: 1,\tavg_G: 164,\tt: 200,\tdt: 14.216ms,\tSimpleTD/loss: 0.0129,\tVanillaPG/loss: -0.00635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 62,\tT: 5,320,\tG: 200,\tavg_r: 1,\tavg_G: 168,\tt: 200,\tdt: 14.087ms,\tSimpleTD/loss: 0.000229,\tVanillaPG/loss: -0.00266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 63,\tT: 5,521,\tG: 200,\tavg_r: 1,\tavg_G: 171,\tt: 200,\tdt: 13.825ms,\tSimpleTD/loss: 0.000679,\tVanillaPG/loss: -0.000324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 64,\tT: 5,697,\tG: 175,\tavg_r: 1,\tavg_G: 171,\tt: 175,\tdt: 14.180ms,\tSimpleTD/loss: 0.166,\tVanillaPG/loss: -0.000734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 175.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 65,\tT: 5,898,\tG: 200,\tavg_r: 1,\tavg_G: 174,\tt: 200,\tdt: 13.633ms,\tSimpleTD/loss: 0.00965,\tVanillaPG/loss: 0.000935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 66,\tT: 6,099,\tG: 200,\tavg_r: 1,\tavg_G: 177,\tt: 200,\tdt: 13.583ms,\tSimpleTD/loss: 0.000416,\tVanillaPG/loss: -0.00693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 67,\tT: 6,300,\tG: 200,\tavg_r: 1,\tavg_G: 179,\tt: 200,\tdt: 13.750ms,\tSimpleTD/loss: 0.00156,\tVanillaPG/loss: -0.00158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 68,\tT: 6,501,\tG: 200,\tavg_r: 1,\tavg_G: 181,\tt: 200,\tdt: 13.967ms,\tSimpleTD/loss: 0.000386,\tVanillaPG/loss: -0.00588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 69,\tT: 6,702,\tG: 200,\tavg_r: 1,\tavg_G: 183,\tt: 200,\tdt: 13.981ms,\tSimpleTD/loss: 0.000785,\tVanillaPG/loss: -0.00588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 70,\tT: 6,903,\tG: 200,\tavg_r: 1,\tavg_G: 185,\tt: 200,\tdt: 14.606ms,\tSimpleTD/loss: 0.000231,\tVanillaPG/loss: -0.00421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 71,\tT: 7,104,\tG: 200,\tavg_r: 1,\tavg_G: 186,\tt: 200,\tdt: 13.575ms,\tSimpleTD/loss: 0.000274,\tVanillaPG/loss: -0.00618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 72,\tT: 7,285,\tG: 180,\tavg_r: 1,\tavg_G: 186,\tt: 180,\tdt: 13.799ms,\tSimpleTD/loss: 0.113,\tVanillaPG/loss: 7e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 180.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 73,\tT: 7,486,\tG: 200,\tavg_r: 1,\tavg_G: 187,\tt: 200,\tdt: 14.362ms,\tSimpleTD/loss: 0.0109,\tVanillaPG/loss: 0.00319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 74,\tT: 7,687,\tG: 200,\tavg_r: 1,\tavg_G: 188,\tt: 200,\tdt: 14.339ms,\tSimpleTD/loss: 0.000679,\tVanillaPG/loss: -0.00303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 75,\tT: 7,850,\tG: 162,\tavg_r: 1,\tavg_G: 186,\tt: 162,\tdt: 14.217ms,\tSimpleTD/loss: 0.0355,\tVanillaPG/loss: 0.00358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 162.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 76,\tT: 8,051,\tG: 200,\tavg_r: 1,\tavg_G: 187,\tt: 200,\tdt: 13.917ms,\tSimpleTD/loss: 0.0246,\tVanillaPG/loss: -0.00133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 77,\tT: 8,252,\tG: 200,\tavg_r: 1,\tavg_G: 188,\tt: 200,\tdt: 14.122ms,\tSimpleTD/loss: 0.000373,\tVanillaPG/loss: -0.00311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 78,\tT: 8,453,\tG: 200,\tavg_r: 1,\tavg_G: 190,\tt: 200,\tdt: 14.327ms,\tSimpleTD/loss: 0.000165,\tVanillaPG/loss: -0.00383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 79,\tT: 8,654,\tG: 200,\tavg_r: 1,\tavg_G: 191,\tt: 200,\tdt: 13.978ms,\tSimpleTD/loss: 0.00278,\tVanillaPG/loss: 0.000705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 80,\tT: 8,809,\tG: 154,\tavg_r: 1,\tavg_G: 187,\tt: 154,\tdt: 13.923ms,\tSimpleTD/loss: 0.0492,\tVanillaPG/loss: 0.000432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 154.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 81,\tT: 9,010,\tG: 200,\tavg_r: 1,\tavg_G: 188,\tt: 200,\tdt: 13.662ms,\tSimpleTD/loss: 0.00568,\tVanillaPG/loss: -0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 82,\tT: 9,208,\tG: 197,\tavg_r: 1,\tavg_G: 189,\tt: 197,\tdt: 13.769ms,\tSimpleTD/loss: 0.0595,\tVanillaPG/loss: 0.0168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 197.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 83,\tT: 9,409,\tG: 200,\tavg_r: 1,\tavg_G: 190,\tt: 200,\tdt: 14.267ms,\tSimpleTD/loss: 0.0125,\tVanillaPG/loss: 0.00667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 84,\tT: 9,610,\tG: 200,\tavg_r: 1,\tavg_G: 191,\tt: 200,\tdt: 14.075ms,\tSimpleTD/loss: 2.88e-05,\tVanillaPG/loss: -0.000837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 85,\tT: 9,811,\tG: 200,\tavg_r: 1,\tavg_G: 192,\tt: 200,\tdt: 13.796ms,\tSimpleTD/loss: 4.14e-06,\tVanillaPG/loss: -0.000494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 86,\tT: 10,012,\tG: 200,\tavg_r: 1,\tavg_G: 193,\tt: 200,\tdt: 14.098ms,\tSimpleTD/loss: 0.000377,\tVanillaPG/loss: 5.22e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 87,\tT: 10,213,\tG: 200,\tavg_r: 1,\tavg_G: 194,\tt: 200,\tdt: 13.836ms,\tSimpleTD/loss: 6.59e-05,\tVanillaPG/loss: -0.00155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 88,\tT: 10,414,\tG: 200,\tavg_r: 1,\tavg_G: 194,\tt: 200,\tdt: 13.609ms,\tSimpleTD/loss: 4.3e-05,\tVanillaPG/loss: -0.000171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[a2c|TrainMonitor|INFO] ep: 89,\tT: 10,615,\tG: 200,\tavg_r: 1,\tavg_G: 195,\tt: 200,\tdt: 13.985ms,\tSimpleTD/loss: 1.88e-05,\tVanillaPG/loss: -0.000526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch reward 209.0\n",
      "Epoch reward 209.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# these optimizers collect batches of grads before applying updates\n",
    "optimizer_v = optax.chain(optax.apply_every(k=32), optax.adam(0.002))\n",
    "optimizer_pi = optax.chain(optax.apply_every(k=32), optax.adam(0.001))\n",
    "\n",
    "\n",
    "# value function and its derived policy\n",
    "v = coax.V(func_v, env)\n",
    "pi = coax.Policy(func_pi, env)\n",
    "\n",
    "# experience tracer\n",
    "tracer = coax.reward_tracing.NStep(n=1, gamma=0.9)\n",
    "\n",
    "# updaters\n",
    "vanilla_pg = coax.policy_objectives.VanillaPG(pi, optimizer=optimizer_pi)\n",
    "simple_td = coax.td_learning.SimpleTD(v, loss_function=mse, optimizer=optimizer_v)\n",
    "\n",
    "\n",
    "# train\n",
    "for ep in range(1000):\n",
    "    s = env.reset()\n",
    "    er = 0\n",
    "    for t in range(env.spec.max_episode_steps):\n",
    "        a = pi(s)\n",
    "        s_next, r, done, info = env.step(a)\n",
    "        \n",
    "        if done and (t == env.spec.max_episode_steps - 1):\n",
    "            r = 1 / (1 - tracer.gamma)\n",
    "        er+=r\n",
    "        tracer.add(s, a, r, done)\n",
    "        while tracer:\n",
    "            transition_batch = tracer.pop()\n",
    "            metrics_v, td_error = simple_td.update(transition_batch, return_td_error=True)\n",
    "            metrics_pi = vanilla_pg.update(transition_batch, td_error)\n",
    "            env.record_metrics(metrics_v)\n",
    "            env.record_metrics(metrics_pi)\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        s = s_next\n",
    "    \n",
    "    print(\"Epoch reward\",er)\n",
    "    # early stopping\n",
    "    if env.avg_G > env.spec.reward_threshold:\n",
    "        break\n",
    "\n",
    "\n",
    "# run env one more time to render\n",
    "#coax.utils.generate_gif(env, policy=pi, filepath=f\"./data/{name}.gif\", duration=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
